{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import FrEIA.framework as Ff\n",
    "import FrEIA.modules as Fm\n",
    "import torch.distributions\n",
    "\n",
    "from data.circleData import make_circles_ssl\n",
    "from data.moonData import make_moons_ssl\n",
    "from data.multiGaussian import make_multigaussian_ssl\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "# x, y, true_labels = make_circles_ssl(n_samples=n_samples, label_ratio=0.05)\n",
    "data1, _, label1 = make_moons_ssl(n_samples=n_samples, label_ratio=0.05, seed=0)\n",
    "# x, y, true_labels = make_squaredata_ssl(n_samples=n_samples, label_ratio=0.05)\n",
    "print(len(data1))\n",
    "plt.scatter(data1[label1 == 0][:,0], data1[label1 == 0][:,1], c='r', s=3)\n",
    "plt.scatter(data1[label1 == 1][:,0], data1[label1 == 1][:,1], c='b', s=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "data2, _, label2 = make_circles_ssl(n_samples=n_samples, label_ratio=0.05)\n",
    "# data2 = data2[label2 == 0]\n",
    "# x2, _, y2 = make_moons_ssl(n_samples=n_samples, label_ratio=0.05, seed=10)\n",
    "# x, y, true_labels = make_squaredata_ssl(n_samples=n_samples, label_ratio=0.05)\n",
    "print(len(data2))\n",
    "plt.scatter(data2[label2 == 0][:,0], data2[label2 == 0][:,1], c='r', s=3)\n",
    "plt.scatter(data2[label2 == 1][:,0], data2[label2 == 1][:,1], c='b', s=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "np.random.seed(2023)\n",
    "mean1 = np.array([-8., 1.])\n",
    "Sigma1 = np.mat(np.array([[0.5, -0.25], [-0.25, 0.5]]))\n",
    "data7 = np.random.multivariate_normal(mean=mean1,cov=Sigma1,size=2000).astype(np.float32)\n",
    "\n",
    "mean2 = np.array([0., 0.])\n",
    "Sigma2 = np.mat(np.array([[1, 0], [0, 1]]))\n",
    "data8 = np.random.multivariate_normal(mean=mean2,cov=Sigma2,size=2000).astype(np.float32)\n",
    "\n",
    "plt.scatter(data7[:,0], data7[:,1], s=3, c='red')\n",
    "plt.scatter(data8[:,0], data8[:,1], s=3, c='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gauss = 8\n",
    "n_samples = 2000 // n_gauss\n",
    "data9 = make_multigaussian_ssl(n_samples=n_samples, n_gauss=n_gauss, radius=8, var=.5)\n",
    "# x2, _, y2 = make_moons_ssl(n_samples=n_samples, label_ratio=0.05, seed=10)\n",
    "# x, y, true_labels = make_squaredata_ssl(n_samples=n_samples, label_ratio=0.05)\n",
    "\n",
    "plt.scatter(data9[:,0], data9[:,1], c='red', s=3)\n",
    "# plt.scatter(data1[:,0], data1[:,1], c='blue', s=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gauss = 8\n",
    "n_samples = 2000 // n_gauss\n",
    "data9 = make_multigaussian_ssl(n_samples=n_samples, n_gauss=n_gauss, radius=8, var=.5)\n",
    "# x2, _, y2 = make_moons_ssl(n_samples=n_samples, label_ratio=0.05, seed=10)\n",
    "# x, y, true_labels = make_squaredata_ssl(n_samples=n_samples, label_ratio=0.05)\n",
    "\n",
    "plt.scatter(data9[:,0], data9[:,1], c='red', s=3)\n",
    "# plt.scatter(data1[:,0], data1[:,1], c='blue', s=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gauss = 8\n",
    "n_samples = 2000 // n_gauss\n",
    "data10 = make_multigaussian_ssl(n_samples=n_samples, n_gauss=n_gauss, start_angle=0, radius=4, var=.5) # radius=2\n",
    "# x2, _, y2 = make_moons_ssl(n_samples=n_samples, label_ratio=0.05, seed=10)\n",
    "# x, y, true_labels = make_squaredata_ssl(n_samples=n_samples, label_ratio=0.05)\n",
    "\n",
    "plt.scatter(data10[:,0], data10[:,1], c='red', s=3)\n",
    "# plt.scatter(data1[:,0], data1[:,1], c='blue', s=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [(t - 10, 2 * t + 1) for t in range(1,11,1)]\n",
    "data13 = np.zeros((2000, 2))\n",
    "for i in range(10):\n",
    "    data13[i * 200: (i + 1) * 200,:] = np.random.randn(200, 2) * 0.65 + mean[i]\n",
    "data13 = data13.astype(np.float32)\n",
    "plt.scatter(data13[:,0], data13[:,1], s=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [(t, 0) for t in range(1,11,1)]\n",
    "data14 = np.zeros((2000, 2))\n",
    "for i in range(10):\n",
    "    data14[i * 200: (i + 1) * 200,:] = np.random.randn(200, 2) * 0.2 + mean[i]\n",
    "data14 = data14.astype(np.float32)\n",
    "plt.scatter(data14[:,0], data14[:,1], s=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDateset(torch.utils.data.Dataset):\n",
    "    def __init__(self, source_data, target_data):\n",
    "        self.x1 = source_data\n",
    "        self.x2 = target_data\n",
    "    def __getitem__(self, index):\n",
    "        x1_sample = self.x1[index]\n",
    "        x2_sample = self.x2[index]\n",
    "        return torch.from_numpy(x1_sample), torch.from_numpy(x2_sample)\n",
    "    def __len__(self):\n",
    "        return len(self.x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = data1\n",
    "target_data = data2\n",
    "plt.scatter(source_data[:,0], source_data[:,1], s=3, c='blue')\n",
    "plt.scatter(target_data[:,0], target_data[:,1], s=3, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    n_samples = int(source.size()[0])+int(target.size()[0])\n",
    "    total = torch.cat([source, target], dim=0)\n",
    "    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "    L2_distance = ((total0-total1)**2).sum(2)\n",
    "    if fix_sigma:\n",
    "        bandwidth = fix_sigma\n",
    "    else:\n",
    "        bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n",
    "    bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "    bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n",
    "    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "    return sum(kernel_val)\n",
    "\n",
    "def mmd(source, target, kernel_type='gaussian_kernel', kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    assert kernel_type in ['gaussian_kernel', 'ed_kernel']\n",
    "\n",
    "    batch_size = int(source.size()[0])\n",
    "    kernels = guassian_kernel(source, target,\n",
    "                            kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n",
    "    XX = kernels[:batch_size, :batch_size]\n",
    "    YY = kernels[batch_size:, batch_size:]\n",
    "    XY = kernels[:batch_size, batch_size:]\n",
    "    YX = kernels[batch_size:, :batch_size]\n",
    "    loss = torch.mean(XX) + torch.mean(YY) - torch.mean(XY) -torch.mean(YX)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:5'\n",
    "dataset = ToyDateset(source_data, target_data)\n",
    "train_dataloader = DataLoader(dataset, batch_size=200, shuffle=True, drop_last=True)\n",
    "\n",
    "n_dim = (2, )\n",
    "\n",
    "def subnet_fc(dims_in, dims_out):\n",
    "    return nn.Sequential(nn.Linear(dims_in, 256), nn.ReLU(),\n",
    "                         nn.Linear(256,  dims_out))\n",
    "\n",
    "n_epoch = 2000\n",
    "\n",
    "flow = Ff.SequenceINN(*n_dim)\n",
    "for _ in range(8):\n",
    "    flow.append(\n",
    "        Fm.AllInOneBlock, \n",
    "        subnet_constructor=subnet_fc, \n",
    "        affine_clamping=2., \n",
    "        permute_soft=True\n",
    "    )\n",
    "\n",
    "\n",
    "flow = flow.to(device)\n",
    "optimizer = torch.optim.Adam(flow.parameters(), lr=3e-3, weight_decay=1e-5) # 3e-3 1e-4\n",
    "\n",
    "\n",
    "for t in range(1, n_epoch + 1):\n",
    "    loss_record = 0. \n",
    "    pot_record = 0.\n",
    "\n",
    "    cnt = 0\n",
    "    for x1, x2 in train_dataloader:\n",
    "        x1, x2 = x1.to(device), x2.to(device)\n",
    "        x2_fake, jac = flow(x1)\n",
    "        x1_fake, _ = flow(x2, rev=True)\n",
    "\n",
    "        loss = mmd(x2_fake, x2, kernel_mul=2, kernel_num=10) + mmd(x1_fake, x1, kernel_mul=2, kernel_num=10) \n",
    "        penalty_ot = 0.5 * torch.mean((x1 - x2_fake) ** 2) + 0.5 * torch.mean((x2 - x1_fake) ** 2)\n",
    "\n",
    "        loss += 0.15 * penalty_ot \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(parameters=flow.parameters(), max_norm=10, norm_type=2)\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_record += loss.item()\n",
    "        pot_record += penalty_ot.item()\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "        loss_avg = loss_record / cnt\n",
    "        pot_avg = pot_record / cnt\n",
    "\n",
    "    if t % 100 == 0:\n",
    "        print('iter: {}, loss: {:.5f}, p_ot: {:.5f}'.format(t, loss_avg, pot_avg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow.load_state_dict(torch.load('mmd_results_m2c/20230502-122106/net_params.pth'))\n",
    "# flow.load_state_dict(torch.load('params_new/mmd/gauss2gauss_o_2.pth'))\n",
    "# flow.load_state_dict(torch.load('params_new/mmd/8gauss28gauss_o.pth'))\n",
    "# flow.load_state_dict(torch.load('params_new/mmd/gauss_classfication_o_1.pth'))\n",
    "\n",
    "source_data = data13\n",
    "target_data = data14\n",
    "with torch.no_grad():\n",
    "    x1_samples_fake, _ = flow(torch.from_numpy(source_data).to(device))\n",
    "    x2_samples_fake, _ = flow(torch.from_numpy(target_data).to(device), rev=True)\n",
    "\n",
    "\n",
    "x1_samples_fake = x1_samples_fake.cpu()\n",
    "x2_samples_fake = x2_samples_fake.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(source_data[:,0], source_data[:,1], s=3, label='original')\n",
    "plt.scatter(x1_samples_fake.numpy()[:,0], x1_samples_fake.numpy()[:,1], s=3, label='generated')\n",
    "\n",
    "plt.legend()\n",
    "for i in range(0,2000,5):\n",
    "    plt.plot([source_data[i,0], x1_samples_fake.numpy()[i,0]], [source_data[i,1], x1_samples_fake.numpy()[i,1]], c='green', linewidth=0.3)\n",
    "# plt.xlim([-2,2])\n",
    "# plt.ylim([-2,2])\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(target_data[:,0], target_data[:,1], s=3, label='original')\n",
    "plt.scatter(x2_samples_fake.numpy()[:,0], x2_samples_fake.numpy()[:,1], s=3, label='generated')\n",
    "plt.legend()\n",
    "# plt.xlim([-2,2])\n",
    "# plt.ylim([-2,2])\n",
    "for i in range(0,2000,5):\n",
    "    plt.plot([target_data[i,0], x2_samples_fake.numpy()[i,0]], [target_data[i,1], x2_samples_fake.numpy()[i,1]], c='green', linewidth=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "df",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
